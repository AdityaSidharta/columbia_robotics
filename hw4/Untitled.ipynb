{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24868109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from functools import lru_cache\n",
    "from random import seed\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imshow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "from image import read_rgb\n",
    "import affordance_model\n",
    "import action_regression_model\n",
    "from common import save_chkpt, load_chkpt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from train import *\n",
    "from affordance_model import *\n",
    "from common import *\n",
    "import torch.nn.functional as F\n",
    " \n",
    "import affordance_model\n",
    "import action_regression_model\n",
    "\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771706e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './data/labels'\n",
    "raw_dataset = RGBDataset(dataset_dir)\n",
    "train_raw_dataset, test_raw_dataset = random_split(\n",
    "    raw_dataset, [int(0.9 * len(raw_dataset)), len(raw_dataset) - int(0.9 * len(raw_dataset))])\n",
    "train_raw_dataset = AugmentedDataset(train_raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282bf909",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = DataLoader(train_raw_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbff2509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f6e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.array(data['rgb'])[0]\n",
    "center_point = np.array(data['center_point'])[0]\n",
    "angle = np.array(data['angle'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e96f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, model_loss: 30 0.0012592010898515582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffordanceModel(\n",
       "  (inc): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (down1): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (down2): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (upconv1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (outc): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class = affordance_model.AffordanceModel\n",
    "model = model_class()\n",
    "chkpt_path = '/home/adityasidharta/columbia/columbia_robotics/hw4/data/affordance/best.ckpt'\n",
    "load_chkpt(model, chkpt_path, torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580b8762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [129, 132, 136],\n",
       "        [130, 133, 136],\n",
       "        [131, 134, 137]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [137, 139, 143],\n",
       "        [135, 136, 140],\n",
       "        [139, 141, 145]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [123, 124, 129],\n",
       "        [116, 117, 121],\n",
       "        [113, 114, 118]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4dfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3085d5a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m angle_norm \u001b[38;5;241m=\u001b[39m (angle \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m180.\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m360.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(\"x : {}, y : {}, angle : {}, x_norm : {}, y_norm : {}, angle_norm : {}\".format(x, y, angle, x_norm, y_norm, angle_norm))\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     18\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray([x_norm, y_norm, angle_norm]))\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "x_max = rgb.shape[0]\n",
    "y_max = rgb.shape[1]\n",
    "\n",
    "# print(\"x_max : {}\".format(x_max))\n",
    "# print(\"y_max : {}\".format(y_max))\n",
    "x = center_point[0]\n",
    "y = center_point[1]\n",
    "\n",
    "x_norm = x / x_max\n",
    "y_norm = y / y_max\n",
    "\n",
    "assert -180. <= angle <= 180.\n",
    "angle_norm = (angle + 180.) / 360.\n",
    "\n",
    "# print(\"x : {}, y : {}, angle : {}, x_norm : {}, y_norm : {}, angle_norm : {}\".format(x, y, angle, x_norm, y_norm, angle_norm))\n",
    "\n",
    "input = torch.from_numpy(np.expand_dims(rgb, 0)).permute(2, 0, 1).type(torch.float32)\n",
    "target = torch.from_numpy(np.array([x_norm, y_norm, angle_norm])).type(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eec1876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbeaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06fa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_obs = np.moveaxis(rgb, -1, 0)\n",
    "rgb_obs = np.expand_dims(rgb_obs, axis = 0)\n",
    "input_value = torch.from_numpy(rgb_obs).type(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5973c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = action_regression_model.ActionRegressionModel\n",
    "model = model_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    action = model.predict(input_value)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(coord, angle), action = recover_action(action), action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 2)\n",
    "x = torch.randn(1, 2)\n",
    "target = torch.randn(1, 2)\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((output[:, 1] - target[:, 1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5320a4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(torch.from_numpy(rgb).flatten(), 1)[0][-1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8080b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9329dc41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(range(1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bba945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7a6db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.mean(1 - torch.cos(output[:,1] - target[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725b3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db8656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((output[:, 1] - target[:, 1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - torch.cos(target[:,1] - target[:,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:,1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61955709",
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:,0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(1) - torch.cos(torch.Tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d15fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3024d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b39ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img = visualize(rgb_obs[0,...], action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db97ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ca21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd4306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_action(\n",
    "        action: np.ndarray, \n",
    "        shape=(128,128)\n",
    "        ) -> Tuple[Tuple[int, int], float]:\n",
    "    \"\"\"\n",
    "    :action: np.ndarray([x,y,angle], dtype=np.float32)\n",
    "    return:\n",
    "    coord: tuple(x, y) in pixel coordinate between 0 and :shape:\n",
    "    angle: float in degrees, clockwise\n",
    "    \"\"\"\n",
    "    # ===============================================================================\n",
    "    x_norm, y_norm, angle_norm = action[0], action[1], action[2]\n",
    "    x = x_norm * shape[0]\n",
    "    y = y_norm * shape[1]\n",
    "    angle = (angle_norm * 360.) - 180.\n",
    "    coord, angle = (x, y), angle\n",
    "    # ===============================================================================\n",
    "    return coord, angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input: np.ndarray, output: np.ndarray, \n",
    "        target: Optional[np.ndarray]=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Visualize rgb input and affordance as a single rgb image.\n",
    "    \"\"\"        \n",
    "    vis_img = (np.moveaxis(input,0,-1).copy() * 255).astype(np.uint8)\n",
    "    # target\n",
    "    if target is not None:\n",
    "        coord, angle = recover_action(target, shape=vis_img.shape[:2])\n",
    "        draw_grasp(vis_img, coord, angle, color=(255,255,255))\n",
    "    # pred\n",
    "    coord, angle = recover_action(output, shape=vis_img.shape[:2])\n",
    "    draw_grasp(vis_img, coord, angle, color=(0,255,0))\n",
    "    return vis_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8890c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df61029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc49a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.moveaxis(rgb, -1, 0)\n",
    "rgb = np.expand_dims(rgb, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a88bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef78ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8067e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4919c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = torch.from_numpy(rgb).type(torch.float32).to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    action = model.predict(input_value)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba68432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df063c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_action(\n",
    "        action: np.ndarray, \n",
    "        shape=(128,128)\n",
    "        ) -> Tuple[Tuple[int, int], float]:\n",
    "    \"\"\"\n",
    "    :action: np.ndarray([x,y,angle], dtype=np.float32)\n",
    "    return:\n",
    "    coord: tuple(x, y) in pixel coordinate between 0 and :shape:\n",
    "    angle: float in degrees, clockwise\n",
    "    \"\"\"\n",
    "    # ===============================================================================\n",
    "    x_norm, y_norm, angle_norm = action[0], action[1], action[2]\n",
    "    x = x_norm * shape[0]\n",
    "    y = y_norm * shape[1]\n",
    "    angle = (angle_norm * 360.) - 180.\n",
    "    coord, angle = (x, y), angle\n",
    "    # ===============================================================================\n",
    "    return coord, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(coord, angle), action = recover_action(action), action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7313e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input: np.ndarray, output: np.ndarray, \n",
    "        target: Optional[np.ndarray]=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Visualize rgb input and affordance as a single rgb image.\n",
    "    \"\"\"        \n",
    "    vis_img = (np.moveaxis(input,0,-1).copy() * 255).astype(np.uint8)\n",
    "    # target\n",
    "    if target is not None:\n",
    "        coord, angle = recover_action(target, shape=vis_img.shape[:2])\n",
    "        draw_grasp(vis_img, coord, angle, color=(255,255,255))\n",
    "    # pred\n",
    "    coord, angle = recover_action(output, shape=vis_img.shape[:2])\n",
    "    draw_grasp(vis_img, coord, angle, color=(0,255,0))\n",
    "    return vis_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001cce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee56c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd43bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762211d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_grasp(rgb, center_point, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600063f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab930c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_action(\n",
    "        action: np.ndarray, \n",
    "        shape=(128,128)\n",
    "        ) -> Tuple[Tuple[int, int], float]:\n",
    "    \"\"\"\n",
    "    :action: np.ndarray([x,y,angle], dtype=np.float32)\n",
    "    return:\n",
    "    coord: tuple(x, y) in pixel coordinate between 0 and :shape:\n",
    "    angle: float in degrees, clockwise\n",
    "    \"\"\"\n",
    "    # ===============================================================================\n",
    "    x_norm, y_norm, angle_norm = action[0], action[1], action[2]\n",
    "    x = int(x_norm * shape[0])\n",
    "    y = int(y_norm * shape[1])\n",
    "    angle = (angle_norm * 360.) - 180.\n",
    "    coord, angle = (x, y), angle\n",
    "    # ===============================================================================\n",
    "    return coord, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f4a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recover_action(np.array([x_norm, y_norm, angle_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b358837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4fb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea6fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9aa506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ee4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98259b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.array(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_angle_index = int(angle / 22.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20788d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "print(\"rgb_obs.shape : {}\".format(rgb.shape))\n",
    "for i in range(8):\n",
    "    seq = iaa.Sequential([iaa.Rotate(i * -22.5)])\n",
    "    rgb_rot = seq(image=rgb)\n",
    "    result.append(rgb_rot)\n",
    "input_value = torch.from_numpy(np.stack(result)).permute(0, 3, 1, 2).type(torch.float32).to(device)\n",
    "with torch.no_grad():\n",
    "    prediction = model.predict(input_value)\n",
    "index = ((prediction == torch.max(prediction)).nonzero())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = (index[3].item(), index[2].item())\n",
    "angle = index[0].item() * 22.5\n",
    "input_value = np.array(input_value.cpu())\n",
    "prediction = np.array(prediction.cpu())\n",
    "vis_list = []\n",
    "for i in range(8):\n",
    "    input = input_value[i,...]\n",
    "    target = prediction[i,...]\n",
    "    vis_image = visualize(input, target)\n",
    "    vis_image[127, :, :] = 127\n",
    "    vis_list.append(vis_image)\n",
    "    if index[0].item() == i:\n",
    "        draw_grasp(vis_image, coord, 0.0)\n",
    "vis_img = np.concatenate([\n",
    "    np.concatenate([vis_list[0], vis_list[1]], axis = 1),\n",
    "    np.concatenate([vis_list[2], vis_list[3]], axis = 1),\n",
    "    np.concatenate([vis_list[4], vis_list[5]], axis = 1),\n",
    "    np.concatenate([vis_list[6], vis_list[7]], axis = 1),\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = prediction[4,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56450d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(output == np.max(output)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prediction == np.max(prediction)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = cmap(output[0])[...,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a37ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img[102, 55, :] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d243b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred_img == np.max(pred_img)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa60e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_grasp(pred_img, (102, 55), 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f645144",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a5a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ((prediction == torch.max(prediction)).nonzero())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[4,0,91, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec62aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af479f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[4,0,91,75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43922fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd705f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(prediction).argmax(keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b881dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ((prediction == torch.max(prediction)).nonzero())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc35090",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input: np.ndarray, output: np.ndarray, \n",
    "        target: Optional[np.ndarray]=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Visualize rgb input and affordance as a single rgb image.\n",
    "    \"\"\"\n",
    "    cmap = cm.get_cmap('viridis')\n",
    "    in_img = np.moveaxis(input, 0, -1)\n",
    "    pred_img = cmap(output[0])[...,:3]\n",
    "    row = [in_img, pred_img]\n",
    "    if target is not None:\n",
    "        gt_img = cmap(target[0])[...,:3]\n",
    "        row.append(gt_img)\n",
    "    img = (np.concatenate(row, axis=1)*255).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab98678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f4c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f6167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7182ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = KeypointsOnImage([\n",
    "    Keypoint(x=center_point[0], y=center_point[1]),\n",
    "], shape=shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Rotate(-angle.item())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aug, kps_aug = seq(image=np.array(rgb), keypoints=kps)\n",
    "x_aug = kps_aug[0].x\n",
    "y_aug = kps_aug[0].y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = get_gaussian_scoremap((img_h, img_w), np.array([x_aug, y_aug]))\n",
    "target = np.expand_dims(target, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba16480",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a091c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_aug = (np.stack([np.moveaxis(target, 0, -1)]*3, axis=2).squeeze() * 255).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe087e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imshow(image_aug + target_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae7491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imshow(target_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b76711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64dfb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8616e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d259a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point_x, center_point_y = center_point[0].item(), center_point[1].item()\n",
    "left_coord, right_coord = get_finger_points(np.array([center_point_x, center_point_y]), angle.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0f4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdb188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49772906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617f828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2802eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_grasp(x, center_point, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = KeypointsOnImage([\n",
    "            Keypoint(x=left_coord[0], y=left_coord[1]),\n",
    "            Keypoint(x=right_coord[0], y=right_coord[1])\n",
    "        ], shape=rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7753bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_delta = 180/8\n",
    "aug_pipeline = iaa.Sometimes(0.99, iaa.Affine(\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-angle_delta/2,angle_delta/2),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ed145",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    aug_pipeline\n",
    "])\n",
    "image_aug, kps_aug = seq(image=np.array(rgb), keypoints=kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_coord_aug_x = kps_aug[0].x\n",
    "left_coord_aug_y = kps_aug[0].y\n",
    "right_coord_aug_x = kps_aug[1].x\n",
    "right_coord_aug_y = kps_aug[1].y\n",
    "\n",
    "center_coord_aug, angle_aug = get_center_angle(np.array([left_coord_aug_x, left_coord_aug_y]),\n",
    "                                               np.array([right_coord_aug_x, right_coord_aug_y]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460875bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'rgb': image_aug,\n",
    "    'center_point': np.array(center_coord_aug, dtype=np.float32),\n",
    "    'angle': np.array(angle_aug, dtype=np.float32)\n",
    "}\n",
    "data_torch = dict()\n",
    "for key, value in data.items():\n",
    "    data_torch[key] = torch.from_numpy(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7578232",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_torch['rgb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c2502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_grasp(image_aug, center_coord_aug, angle_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ccd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c90922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = affordance_model.AffordanceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb09ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('data', 'affordance')\n",
    "chkpt_path = os.path.join(model_dir, 'best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model_class()\n",
    "model.to(device)\n",
    "load_chkpt(model, chkpt_path, device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1706393",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path =  '/home/adityasidharta/columbia/columbia_robotics/hw4/data/labels/labels.json'\n",
    "labels = json.load(open(labels_path, 'r'))\n",
    "label_pairs = list()\n",
    "for key, value in labels.items():\n",
    "    for i, label in enumerate(value):\n",
    "        label_pairs.append((\n",
    "            '{}_{}'.format(key, i),\n",
    "            label\n",
    "        ))\n",
    "labels_dir = '/home/adityasidharta/columbia/columbia_robotics/hw4/data/labels/'\n",
    "label_pairs = label_pairs\n",
    "key, label = label_pairs[5]\n",
    "img_path = os.path.join(labels_dir, '{}_rgb.png'.format(key))\n",
    "rgb = read_rgb(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31481260",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord, angle, vis_img = model.predict_grasp(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1af638",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 8*1*128*128).reshape(8,1,128,128)\n",
    "(a == 6691).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec78473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_raw_dataset, test_raw_dataset = random_split(\n",
    "    raw_dataset, [int(0.9 * len(raw_dataset)), len(raw_dataset) - int(0.9 * len(raw_dataset))])\n",
    "dataset_class = affordance_model.AffordanceDataset\n",
    "train_dataset = dataset_class(train_raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c378973",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcfebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d60926",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53116d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968abfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19528503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd0abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d6db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = torch.from_numpy(rgb).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec644db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = TF.rotate(rg, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.array(result.permute(1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f81971",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(8):\n",
    "    seq = iaa.Sequential([iaa.Rotate(i * 22.5)])\n",
    "    rgb_rot = seq(image=rgb)\n",
    "    result.append(rgb_rot)\n",
    "input_value = torch.from_numpy(np.stack(result)).permute(0, 3, 1, 2).type(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78075ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119eeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = model.predict(input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5623df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ((prediction == torch.max(prediction)).nonzero())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0372937",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input_value.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0364214",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = input_value.cpu()\n",
    "prediction = prediction.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdede992",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(np.array(input_value), np.array(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617df02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img = np.moveaxis(np.array(input_value), 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ed818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "from common import draw_grasp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52474422",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b548efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = np.array(input_value.cpu())\n",
    "prediction = np.array(prediction.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a883a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input_value[0,...]\n",
    "target = prediction[0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25227d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_image = visualize(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f16e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_image[127, :, :] = int(255 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad702b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07502d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7911f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    input = input_value[i,...]\n",
    "    target = prediction[i,...]\n",
    "    vis_list.append(visualize(input, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(input, target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c838640",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_list = []\n",
    "for i in range(8):\n",
    "    input = input_value[i,...]\n",
    "    target = prediction[i,...]\n",
    "    vis_image = visualize(input, target)\n",
    "    vis_image[127, :, :] = 0\n",
    "    vis_list.append(vis_image)\n",
    "vis_img = np.concatenate([\n",
    "    np.concatenate([vis_list[0], vis_list[1]], axis = 1),\n",
    "    np.concatenate([vis_list[2], vis_list[3]], axis = 1),\n",
    "    np.concatenate([vis_list[4], vis_list[5]], axis = 1),\n",
    "    np.concatenate([vis_list[6], vis_list[7]], axis = 1),\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744446b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a554fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305ffde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589dbe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.concatenate([[vis_list[0], vis_list[1]],\n",
    "         [vis_list[2], vis_list[3]],\n",
    "         [vis_list[4], vis_list[5]],\n",
    "         [vis_list[6], vis_list[7]],]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68201ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ddb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ab816",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = cmap(np.array(prediction)[0])[...,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d060de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7b202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb05d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize(input_value.cpu(), prediction.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bccb7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a57f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c85756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20620e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6191aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc2a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42730406",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(8):\n",
    "    seq = iaa.Sequential([iaa.Rotate(i * 22.5)])\n",
    "    rgb_rot = seq(image=rgb)\n",
    "    result.append(rgb_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = torch.from_numpy(np.stack(result)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9734782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = affordance_model.AffordanceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b879803",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14858c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7870c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac838f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rgb_cached(file_path):\n",
    "    return read_rgb(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09246518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ceee81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1988d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_delta = 180/8\n",
    "aug_pipeline = iaa.Sometimes(0.7, iaa.Affine(\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-angle_delta/2,angle_delta/2),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_angle(\n",
    "        left_coord: np.ndarray, \n",
    "        right_coord: np.ndarray\n",
    "        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert the pixel coordinate of left and right fingers to \n",
    "    gripper center and angle.\n",
    "    return:\n",
    "    center_coord: np.ndarray([x,y], dtype=np.float32)\n",
    "    angle: float\n",
    "    \"\"\"\n",
    "    # TODO: complete this function\n",
    "    # Why do we need this function?\n",
    "    # Hint: read get_finger_points\n",
    "    # Hint: it's a hack\n",
    "    # ===============================================================================\n",
    "    center_coord = np.array([(left_coord[0] + right_coord[0]) / 2, (left_coord[1] + right_coord[1]) / 2])\n",
    "    x, y = right_coord - center_coord\n",
    "    angle = np.arctan2(y, x) * 180. / np.pi\n",
    "    # ===============================================================================\n",
    "    return center_coord, angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point_x, center_point_y = center_point[0].item(), center_point[1].item()\n",
    "left_coord, right_coord = get_finger_points(np.array([center_point_x, center_point_y]), angle.item())\n",
    "kps = KeypointsOnImage([\n",
    "    Keypoint(x=left_coord[0], y=left_coord[1]),\n",
    "    Keypoint(x=right_coord[0], y=right_coord[1])\n",
    "], shape=rgb.shape)\n",
    "seq = iaa.Sequential([\n",
    "    aug_pipeline\n",
    "])\n",
    "image_aug, kps_aug = seq(image=np.array(rgb), keypoints=kps)\n",
    "left_coord_aug_x = kps_aug[0].x\n",
    "left_coord_aug_y = kps_aug[0].y\n",
    "right_coord_aug_x = kps_aug[1].x\n",
    "right_coord_aug_y = kps_aug[1].y\n",
    "\n",
    "center_coord_aug, angle_aug = get_center_angle(np.array([left_coord_aug_x, left_coord_aug_y]),\n",
    "                                               np.array([right_coord_aug_x, right_coord_aug_y]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(kps.draw_on_image(rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(kps_aug.draw_on_image(image_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(image_aug).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_coord_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f222b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(angle_aug).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0., 360., 360./8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in np.arange(0., 360., 360./8.):\n",
    "    seq = iaa.Sequential([iaa.Rotate(i)])\n",
    "    rgb_rot = seq(image=rgb)\n",
    "    result.append(rgb_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d973fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a22b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = torch.from_numpy(np.stack(result)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "((input_value==torch.max(input_value)).nonzero())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value[  6,  21,   0,   2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point = np.array(label[:2], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_point = np.array(label[2], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b898d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = torch.from_numpy(rgb)\n",
    "center_point = torch.from_numpy(center_point)\n",
    "angle = torch.from_numpy(angle_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = KeypointsOnImage([\n",
    "    Keypoint(x=center_point[0], y=center_point[1]),\n",
    "], shape=rgb.shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Rotate(-angle.item())\n",
    "])\n",
    "\n",
    "image_aug, kps_aug = seq(image=np.array(rgb), keypoints=kps)\n",
    "x_aug = kps_aug[0].x\n",
    "y_aug = kps_aug[0].y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_after = kps_aug.draw_on_image(image_aug, size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9341fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.array(rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(8):\n",
    "    seq = iaa.Sequential([iaa.Rotate(i * 22.5)])\n",
    "    rgb_rot = seq(image=rgb)\n",
    "    result.append(rgb_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = torch.from_numpy(np.stack(result)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(np.array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "\n",
    "a = np.zeros([128, 128, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "from common import draw_grasp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input: np.ndarray, output: np.ndarray, \n",
    "            target: Optional[np.ndarray]=None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Visualize rgb input and affordance as a single rgb image.\n",
    "        \"\"\"\n",
    "        cmap = cm.get_cmap('viridis')\n",
    "        in_img = np.moveaxis(input, 0, -1)\n",
    "        pred_img = cmap(output[0])[...,:3]\n",
    "        row = [in_img, pred_img]\n",
    "        if target is not None:\n",
    "            gt_img = cmap(target[0])[...,:3]\n",
    "            row.append(gt_img)\n",
    "        img = (np.concatenate(row, axis=1)*255).astype(np.uint8)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b8daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf57d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8845135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d9f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(image_aug).permute(2, 0, 1).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dec9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = KeypointsOnImage([\n",
    "    Keypoint(x=center_point[0], y=center_point[1]),\n",
    "], shape=rgb.shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Rotate(-angle_point.item())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9304f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aug, kps_aug = seq(image=np.array(rgb), keypoints=kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_aug[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_aug[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13649f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_after = kps_aug.draw_on_image(image_aug, size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1aedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_scoremap(\n",
    "        shape: Tuple[int, int], \n",
    "        keypoint: np.ndarray, \n",
    "        sigma: float=1, dtype=np.float32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a image of shape=:shape:, generate a Gaussian distribtuion\n",
    "    centered at :keypont: with standard deviation :sigma: pixels.\n",
    "    keypoint: shape=(2,)\n",
    "    \"\"\"\n",
    "    coord_img = np.moveaxis(np.indices(shape),0,-1).astype(dtype)\n",
    "    sqrt_dist_img = np.square(np.linalg.norm(\n",
    "        coord_img - keypoint[::-1].astype(dtype), axis=-1))\n",
    "    scoremap = np.exp(-0.5/np.square(sigma)*sqrt_dist_img)\n",
    "    return scoremap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = get_gaussian_scoremap((128, 128), np.array([x_aug, y_aug]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.expand_dims(target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff00a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def angle_between(p1, p2):\n",
    "    ang1 = np.arctan2(*p1[::-1])\n",
    "    ang2 = np.arctan2(*p2[::-1])\n",
    "    return np.rad2deg((ang1 - ang2) % (2 * np.pi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finger_points(\n",
    "        center_point: np.ndarray, \n",
    "        angle: float, width: int=10\n",
    "        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given the pick position and angle in pixel space,\n",
    "    return the position of left and right fingers of the gripper\n",
    "    given the gripper width.\n",
    "    \"\"\"\n",
    "    center_coord = np.array(center_point, dtype=np.float32)\n",
    "    rad = angle / 180 * np.pi\n",
    "    direction = np.array([np.cos(rad), np.sin(rad)], dtype=np.float32)\n",
    "    left_coord = center_coord - direction * width\n",
    "    right_coord = center_coord + direction * width\n",
    "    return left_coord, right_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90b49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab37afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_points = np.array([50., 60.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = get_finger_points(center_points, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ae3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c35b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_points = np.array([(left[0] + right[0]) / 2, (left[1] + right[1]) / 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac260555",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = right - center_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115479",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arctan2(y, x) * 180. / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774810c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0ef16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_between(center_points, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15244ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f84382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imshow( + image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbe368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670337d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066fcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137322cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr, cc = draw.circle_perimeter(label[1], label[0], 3)\n",
    "rgb[rr, cc] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da53d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6729cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6644d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, label = label_pairs[7]\n",
    "img_path = os.path.join(labels_dir, '{}_rgb.png'.format(key))\n",
    "rgb = read_rgb_cached(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cfe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de346fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "image = rgb\n",
    "kps = KeypointsOnImage([\n",
    "    Keypoint(x=label[0], y=label[1]),\n",
    "], shape=image.shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Rotate(-label[2]) # rotate by exactly 10deg and scale to 50-70%, affects keypoints\n",
    "])\n",
    "\n",
    "# Augment keypoints and images.\n",
    "image_aug, kps_aug = seq(image=image, keypoints=kps)\n",
    "\n",
    "# print coordinates before/after augmentation (see below)\n",
    "# use after.x_int and after.y_int to get rounded integer coordinates\n",
    "for i in range(len(kps.keypoints)):\n",
    "    before = kps.keypoints[i]\n",
    "    after = kps_aug.keypoints[i]\n",
    "    print(\"Keypoint %d: (%.8f, %.8f) -> (%.8f, %.8f)\" % (\n",
    "        i, before.x, before.y, after.x, after.y)\n",
    "    )\n",
    "\n",
    "# image with keypoints before/after augmentation (shown below)\n",
    "image_before = kps.draw_on_image(image, size=7)\n",
    "image_after = kps_aug.draw_on_image(image_aug, size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3410f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c480f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(image_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(image_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224db5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba84635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fcd06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comsw4733_hw4",
   "language": "python",
   "name": "comsw4733_hw4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
